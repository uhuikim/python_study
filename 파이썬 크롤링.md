# python 데이터 크롤링 하기

 수업시간에 배운 크롤링 방법 두가지(어떤 라이브러리가 어떤 함수를 가지고 있는지 암기하기)

1. BeatifulSoup & requests
2. Selenium & chromedriver 

------

#### < BeautifulSoup>

-  정의 : HTML 및 XML파일에서 원하는 데이터를 손쉽게 Parsing 할 수 있는 Python 라이브러리
  
-  html등의 코드를 python이 이해하는 객체구조로 변환하는 parsing을 맡고 있음
  
  - parsing이란? 일련의 문자열을 의미있는 token(어휘 분석의 단위)으로 분해하고 그것들로 이루어진 parse tree를 만드는 과정
  
  - requests 모듈 :
  
    python에서 http요청을 보내는 모듈(http통신을 위한 파이썬 라이브러리)
  
    requests는 html을  python이 이해하는 객체구조로 만들어 주지는 못해 beatifulsoup을 이용한다. 



##### url에서 html 소스코드 가져오기

```python
from bs4 import BeatifulSoup
import requests 

#크롤링 할 url저장
url = "www.naver.com"
#url페이지에 접속하고 페이지의 내용을 response에 대입 
response = requests.get(url)
#응답정보 한글 설정
response.encoding = "UTF8"
response.text

#응답정보를 저장하고 응답정보에서 정보를 추출하는 beatifulsoup 객체 생성
# 첫 인자는 html 소스코드, 두번째 인자는 어떤 parser를 이용할지 명시
soup = BeatifulSoup(response.text , 'html.parser')
```

##### 태그를 이용한 정보 추출 방법 

```python
#body태그안에 포함된 내용 리턴
body = soup.body
#body 태그안에 포함된 h1 태그를 리턴
h1=body.h1
#h1태그에 포함된 문자열 리턴 
h1.string
```

##### id속성을 이용한 정보추출(id값은 유일한 값)

```python
soup = BeautifulSoup(response.text , 'html.parser')
#<html>
#<body>
#<h1 id='title'>스크레핑이란?</h1>
#<p id='body01'>웹 페이지를 분석하는 것</p>
#<p id='body02'>원 하는 데이터를 추출 하는것</p>
#</body>
#</html>

#id속성이 title인 객체 리턴 
title = soup.find(id='title')
#---> <h1 id='title'>스크레핑이란?</h1>

#id속성이 body01인 객체 리턴
body01 = soup.find(id="body01")
#---><p id='body01'>웹 페이지를 분석하는 것</p>
```

#####  find_all함수를 이용한 정보 추출

```python
#find_all() 메서드로 a태그 추출하기
links = soup.find_all("a")
```

#####  select_one & select 를 이용한 정보 추출 

f12버튼 / copy / copy selector 이용

```python
import requests
from bs4 import BeautifulSoup

url = 'https://gist.githubusercontent.com/eduChange-hphk/3f1770767ef61105b608244f0d1433f7/raw/23ad99a4786d88b76667f5b7d312cc0d36318c7b/selector.html'

response = requests.get(url)

html = response.text
soup = BeautifulSoup(html, 'html.parser')
select = soup.select_one('body > ol.subway > li:nth-child(3)')

print(select.text)

#ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ

import requests
from bs4 import BeautifulSoup

url = "http://www.naver.com"
response = requests.get(url)
html = response.text
soup = BeautifulSoup(html,'html.parser')
select = soup.select('#PM_ID_ct > div.header > div.section_navbar > div.area_hotkeyword.PM_CL_realtimeKeyword_base > div.ah_roll.PM_CL_realtimeKeyword_rolling_base > div > ul >li >a >span.ah_k')
qq = []
for i in select :
    qq.append(i.text)
    
print(qq[0:10])
```

##### 실습해보기

``` python

```

------

#### < Selenium>





